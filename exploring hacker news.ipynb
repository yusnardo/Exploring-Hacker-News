{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style = \"text-align:justify\">\n",
    "In this project, i will work with a data set of submissions to popular technology site [Hacker News](https://news.ycombinator.com/). <br> <br>\n",
    "\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result. <br> <br>\n",
    "\n",
    "You can find the data set [here](https://www.kaggle.com/hacker-news/hacker-news-posts), but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. Below are descriptions of the columns: <br><br>\n",
    "</div>\n",
    "\n",
    "1. **id**: The unique identifier from Hacker News for the post <br>\n",
    "2. **title**: The title of the post<br>\n",
    "3. **url**: The URL that the posts links to, if it the post has a URL<br>\n",
    "4. **num_points**: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes<br>\n",
    "5. **num_comments**: The number of comments that were made on the post<br>\n",
    "6. **author**: The username of the person who submitted the post<br>\n",
    "7. **created_at**: The date and time at which the post was submitted<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn = list(reader(open('D:/Dataset/exploring_hacker_news/hacker_news.csv')))\n",
    "headers = hn[0]\n",
    "hn = hn[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01'],\n",
       " ['10301696',\n",
       "  'Note by Note: The Making of Steinway L1037 (2007)',\n",
       "  'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
       "  '8',\n",
       "  '2',\n",
       "  'walterbell',\n",
       "  '9/30/2015 4:12']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for i in hn:\n",
    "    title = i[1].lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(i)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(i)\n",
    "    else:\n",
    "        other_posts.append(i)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12296411',\n",
       "  'Ask HN: How to improve my personal website?',\n",
       "  '',\n",
       "  '2',\n",
       "  '6',\n",
       "  'ahmedbaracat',\n",
       "  '8/16/2016 9:55'],\n",
       " ['10610020',\n",
       "  'Ask HN: Am I the only one outraged by Twitter shutting down share counts?',\n",
       "  '',\n",
       "  '28',\n",
       "  '29',\n",
       "  'tkfx',\n",
       "  '11/22/2015 13:43'],\n",
       " ['11610310',\n",
       "  'Ask HN: Aby recent changes to CSS that broke mobile?',\n",
       "  '',\n",
       "  '1',\n",
       "  '1',\n",
       "  'polskibus',\n",
       "  '5/2/2016 10:14'],\n",
       " ['12210105',\n",
       "  'Ask HN: Looking for Employee #3 How do I do it?',\n",
       "  '',\n",
       "  '1',\n",
       "  '3',\n",
       "  'sph130',\n",
       "  '8/2/2016 14:20'],\n",
       " ['10394168',\n",
       "  'Ask HN: Someone offered to buy my browser extension from me. What now?',\n",
       "  '',\n",
       "  '28',\n",
       "  '17',\n",
       "  'roykolak',\n",
       "  '10/15/2015 16:38']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_posts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10627194',\n",
       "  'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform',\n",
       "  'https://iot.seeed.cc',\n",
       "  '26',\n",
       "  '22',\n",
       "  'kfihihc',\n",
       "  '11/25/2015 14:03'],\n",
       " ['10646440',\n",
       "  'Show HN: Something pointless I made',\n",
       "  'http://dn.ht/picklecat/',\n",
       "  '747',\n",
       "  '102',\n",
       "  'dhotson',\n",
       "  '11/29/2015 22:46'],\n",
       " ['11590768',\n",
       "  'Show HN: Shanhu.io, a programming playground powered by e8vm',\n",
       "  'https://shanhu.io',\n",
       "  '1',\n",
       "  '1',\n",
       "  'h8liu',\n",
       "  '4/28/2016 18:05'],\n",
       " ['12178806',\n",
       "  'Show HN: Webscope  Easy way for web developers to communicate with Clients',\n",
       "  'http://webscopeapp.com',\n",
       "  '3',\n",
       "  '3',\n",
       "  'fastbrick',\n",
       "  '7/28/2016 7:11'],\n",
       " ['10872799',\n",
       "  'Show HN: GeoScreenshot  Easily test Geo-IP based web pages',\n",
       "  'https://www.geoscreenshot.com/',\n",
       "  '1',\n",
       "  '9',\n",
       "  'kpsychwave',\n",
       "  '1/9/2016 20:45']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_posts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for i in ask_posts:\n",
    "    num_comments = int(i[4])\n",
    "    total_ask_comments += num_comments\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "for i in show_posts:\n",
    "    num_comments = int(i[4])\n",
    "    total_show_comments += num_comments\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align:justify\">\n",
    "On average, ask posts in our sample receive approximately 14 comments, whereas show posts receive approximately 10. Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Amount of Ask Posts and Comments by Hour Created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align:justify\">\n",
    "Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "</div>\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "result_list = []\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for i in ask_posts:\n",
    "    created_at = i[6]\n",
    "    num_comments = int(i[4])\n",
    "    result_list.append([created_at, num_comments])\n",
    "for j in result_list:\n",
    "    date = j[0]\n",
    "    num_comments = j[1]\n",
    "    date_time = dt.datetime.strptime(date, date_format).strftime(\"%H\")\n",
    "    \n",
    "    if date_time in counts_by_hour:\n",
    "        counts_by_hour[date_time] += 1\n",
    "        comments_by_hour[date_time] += num_comments\n",
    "    else:\n",
    "        counts_by_hour[date_time] = 1\n",
    "        comments_by_hour[date_time] = num_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for i in comments_by_hour:\n",
    "    avg_by_hour.append([i, comments_by_hour[i] / counts_by_hour[i]])\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5777777777777775, '09'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [16.796296296296298, '16'], [7.985294117647059, '23'], [9.41095890410959, '12'], [11.46, '17'], [38.5948275862069, '15'], [16.009174311926607, '21'], [21.525, '20'], [23.810344827586206, '02'], [13.20183486238532, '18'], [7.796296296296297, '03'], [10.08695652173913, '05'], [10.8, '19'], [11.383333333333333, '01'], [6.746478873239437, '22'], [10.25, '08'], [7.170212765957447, '04'], [8.127272727272727, '00'], [9.022727272727273, '06'], [7.852941176470588, '07'], [11.051724137931034, '11']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [13.20183486238532, '18'],\n",
       " [11.46, '17'],\n",
       " [11.383333333333333, '01'],\n",
       " [11.051724137931034, '11'],\n",
       " [10.8, '19'],\n",
       " [10.25, '08'],\n",
       " [10.08695652173913, '05'],\n",
       " [9.41095890410959, '12'],\n",
       " [9.022727272727273, '06'],\n",
       " [8.127272727272727, '00'],\n",
       " [7.985294117647059, '23'],\n",
       " [7.852941176470588, '07'],\n",
       " [7.796296296296297, '03'],\n",
       " [7.170212765957447, '04'],\n",
       " [6.746478873239437, '22'],\n",
       " [5.5777777777777775, '09']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_swap[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:00: 38.59 comments per post\n",
      "02:00: 23.81 comments per post\n",
      "20:00: 21.52 comments per post\n",
      "16:00: 16.80 comments per post\n",
      "21:00: 16.01 comments per post\n",
      "13:00: 14.74 comments per post\n",
      "10:00: 13.44 comments per post\n",
      "14:00: 13.23 comments per post\n",
      "18:00: 13.20 comments per post\n",
      "17:00: 11.46 comments per post\n",
      "01:00: 11.38 comments per post\n",
      "11:00: 11.05 comments per post\n",
      "19:00: 10.80 comments per post\n",
      "08:00: 10.25 comments per post\n",
      "05:00: 10.09 comments per post\n",
      "12:00: 9.41 comments per post\n",
      "06:00: 9.02 comments per post\n",
      "00:00: 8.13 comments per post\n",
      "23:00: 7.99 comments per post\n",
      "07:00: 7.85 comments per post\n",
      "03:00: 7.80 comments per post\n",
      "04:00: 7.17 comments per post\n",
      "22:00: 6.75 comments per post\n",
      "09:00: 5.58 comments per post\n"
     ]
    }
   ],
   "source": [
    "for i in sorted_swap:\n",
    "    hour = i[1]\n",
    "    average = i[0]\n",
    "    string = \"{hour}: {average:.2f} comments per post\"\n",
    "    print(string.format(hour=dt.datetime.strptime(hour, \"%H\").strftime(\"%H:%M\"), average = average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align:justify\">\n",
    "The hour that receives the most comments per post on average is 15:00, with an average of 38.59 comments per post. There's about a 60% increase in the number of comments between the hours with the highest and second highest average number of comments.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"text-align:justify\">\n",
    "In this project, we analyzed ask posts and show posts to determine which type of post and time receive the most comments on average. Based on our analysis, to maximize the amount of comments a post receives, we'd recommend the post be categorized as ask post and created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est). \n",
    "\n",
    "However, it should be noted that the data set we analyzed excluded posts without any comments. Given that, it's more accurate to say that of the posts that received comments, ask posts received more comments on average and ask posts created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est) received the most comments on average.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
